<h1><span style="color: #000000;">Conclusion</span></h1>
<h3 style="text-align: justify;"><span style="text-align: justify; color: #0000ff;"><br /><span style="color: #3366ff;">We see that the decision tree classification has given us a very accurate model (0.92) which also has a good recall (0.95). This resulting F-Score of 0.94 indicates a high predictive power for our decision tree model</span></span></h3>
<h3 style="text-align: justify;"><span style="color: #3366ff;">For our particular set of variables, we found that, due to the limitations of our datasets, the decision tree was better able to predict the purchase intention of the shoppers than the cluster models. The Decision Tree had a 0.94 higher F-score, whereas the Clustering model had a 0.72 F-Score. With the Decision Tree we were able to predict that, during October and November, the customer was more likely to make a purchase. We can also increase the probability of sales by concentrating on three metrics; increase the page ranking, decrease the bounce rate, and pay attention to the types of items listed on administrative form '5' and below pages.</span></h3>
<h3><strong><a title="Decision Tree " href="https://raw.githubusercontent.com/nunufung/cetm46/master/decisontree.png" target="_blank" rel="noopener">Running the decision tree algorithm from the &ldquo;rpart&rdquo; library:</a></strong></h3>